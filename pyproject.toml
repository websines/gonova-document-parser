[project]
name = "document-parser"
version = "0.1.0"
description = "Per-page routed document processing API using DeepSeek-OCR and Nanonets-OCR2 via external vLLM servers"
requires-python = ">=3.10,<3.13"
dependencies = [
    # Core async processing (no Docling - uses pure async + vLLM)
    "openai>=1.0.0",  # AsyncOpenAI for vLLM communication
    "pillow>=10.0.0",
    "pypdf>=5.0.0",  # Fast per-page classification
    "pdf2image>=1.17.0",  # PDF to image conversion
    "pydantic>=2.10.0",
    "pydantic-settings>=2.6.0",
    "python-dotenv>=1.0.0",
    "rich>=13.0.0",
    "typer>=0.12.0",
    "loguru>=0.7.0",
]

[project.optional-dependencies]
# NOTE: vLLM is NOT needed locally - it runs externally on your host machine
# This app only connects to vLLM servers via OpenAI-compatible HTTP API
api = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.32.0",
]
db = [
    "neo4j>=5.0.0",
    "redis>=5.0.0",
]
legacy = [
    # Legacy Docling-based processors (deepseek_processor.py, nanonets_processor.py)
    # NOT used by default - async_processor.py is now the primary processor
    "docling[vlm]>=2.0.0",
    "transformers>=4.46.0",
    "torch>=2.6.0",
]
enrichment = [
    # Optional Granite enrichment layer
    "transformers>=4.46.0",
    "torch>=2.6.0",
]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "black>=24.0.0",
    "ruff>=0.7.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.black]
line-length = 100
target-version = ["py310", "py311", "py312"]

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W"]
ignore = ["E501"]

[project.scripts]
docparse = "document_parser.cli:app"
docparse-api = "document_parser.api:main"
