# =============================================================================
# Document Parser with MinerU 2.5 - Configuration
# =============================================================================
# Copy this file to .env and update values for your setup

# =============================================================================
# MinerU vLLM Server (HOST ON PRODUCTION PC, NOT THIS DEV PC)
# =============================================================================
# This API server connects to an external vLLM server running MinerU 2.5
# The vLLM server should be running on your production/GPU PC

MINERU_VLLM_URL=http://localhost:4444
MINERU_MODEL=opendatalab/MinerU2.5-2509-1.2B

# =============================================================================
# Processing Configuration
# =============================================================================
BATCH_SIZE=64            # Number of pages per batch (reduces memory usage)
CONCURRENCY=16           # Number of concurrent pages within each batch
MAX_PAGES_PER_BATCH=1000 # Maximum pages per job
TIMEOUT=600              # Request timeout in seconds
MAX_RETRIES=3            # Maximum retry attempts for failed requests

# How it works:
# - PDF is split into batches of BATCH_SIZE pages (e.g., 64 pages)
# - Within each batch, CONCURRENCY pages are processed in parallel (e.g., 16 at a time)
# - Example: 669 pages = 11 batches of 64 pages, each batch processes 16 pages concurrently
# - This prevents overwhelming memory and the vLLM server

# =============================================================================
# API Server (RUNS ON THIS DEV PC)
# =============================================================================
API_HOST=0.0.0.0
API_PORT=1233

# =============================================================================
# Redis Configuration (FOR JOB QUEUE)
# =============================================================================
REDIS_URL=redis://localhost:6379/0
NUM_WORKERS=2            # Number of background workers for async jobs

# =============================================================================
# Output Configuration
# =============================================================================
OUTPUT_DIR=./output
CACHE_DIR=./cache
LOG_LEVEL=INFO

# =============================================================================
# Optional: Neo4j Graph Database
# =============================================================================
# NEO4J_URI=bolt://localhost:7687
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=password

# =============================================================================
# SETUP INSTRUCTIONS FOR PRODUCTION PC (GPU/vLLM HOST)
# =============================================================================
#
# 1. Install vLLM on production PC:
#    pip install vllm
#
# 2. Download MinerU 2.5 model (automatic on first run):
#    The model will auto-download from HuggingFace
#
# 3. Start vLLM server on production PC:
#    vllm serve opendatalab/MinerU2.5-2509-1.2B \
#      --host 0.0.0.0 \
#      --port 4444 \
#      --gpu-memory-utilization 0.9 \
#      --trust-remote-code
#
# 4. Update MINERU_VLLM_URL above with production PC IP:
#    MINERU_VLLM_URL=http://192.168.1.100:4444
#
# 5. Start API server on this dev PC:
#    python -m document_parser.api
#
# =============================================================================
# PERFORMANCE NOTES
# =============================================================================
# - MinerU 2.5 is only 1.2B params (very light!)
# - Replaces old multi-model system (DeepSeek + Nanonets + Granite)
# - 60-70% less VRAM usage
# - 2-3x faster processing
# - Handles all document types: text, tables, formulas, signatures, handwriting
# - Supports 84 languages
#
# Expected Speed:
# - With CONCURRENCY=16: ~2-3 pages/sec on A100
# - 669-page PDF: ~240-365 seconds (4-6 minutes) vs old 729s (12 minutes)
# =============================================================================
